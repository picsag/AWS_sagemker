{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Version': '2012-10-17',\n",
       " 'Statement': [{'Sid': 'VisualEditor0',\n",
       "   'Effect': 'Allow',\n",
       "   'Action': ['sagemaker:DescribeEndpointConfig',\n",
       "    'sagemaker:DescribeEndpoint',\n",
       "    'sagemaker:InvokeEndpoint'],\n",
       "   'Resource': '*'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boto3 SageMaker Invoke Endpoint\n",
    "# This example shows how to invoke SageMaker Endpoint from outside of AWS environment using Boto3 SDK\n",
    "# Boto is the Amazon Web Services (AWS) SDK for Python\n",
    "# https://boto3.amazonaws.com/v1/documentation/api/latest/index.html\n",
    "\n",
    "# Common Data Formats\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-inference.html\n",
    "\n",
    "# Endpoint: XGBoost - Kaggle Bike Rental - Regressor Trained in XGBoost Lectures\n",
    "# Makesure Endpoint is deployed before running this example\n",
    "# \n",
    "# Reference:\n",
    "#  https://github.com/awslabs/amazon-sagemaker-examples\n",
    "\n",
    "# NOTE: SageMaker SDK now requires additional permissions DescribeEndpoint, DescribeEndpointConfig in-addition to InvokeEndpoint\n",
    "#   boto3 SDK requires just InvokeEndpoint permission.\n",
    "#   Please update SageMakerInvokeEndpoint permissions to reflect this policy document:\n",
    "#   Logon with my_admin account and update permissions (IAM->Policies->SageMakerInvokeEndpoint->Edit Policy)\n",
    "#   \n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"VisualEditor0\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"sagemaker:DescribeEndpointConfig\",\n",
    "                \"sagemaker:DescribeEndpoint\",\n",
    "                \"sagemaker:InvokeEndpoint\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import math\n",
    "import dateutil\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a session with AWS\n",
    "# Specify credentials and region to be used for this session.\n",
    "# We will use a ml_user_predict credentials that has limited privileges\n",
    "boto_session = boto3.Session(profile_name='user_tmd',region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire a SageMaker Runtime client for us-east-1 region\n",
    "client = boto_session.client(service_name='sagemaker-runtime',region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify Your Endpoint Name\n",
    "endpoint_name = 'xgboost-biketrain-v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data\n",
    "#datetime,season,holiday,workingday,weather,temp,atemp,humidity,windspeed,casual,registered,count\n",
    "# Actual=562\n",
    "sample_one = ['2012-12-19 17:00:00',4,0,1,1,16.4,20.455,50,26.0027]\n",
    "# Actual=569\n",
    "sample_two = ['2012-12-19 18:00:00',4,0,1,1,15.58,19.695,50,23.9994]\n",
    "# Actual=4\n",
    "sample_three = ['2012-12-10 01:00:00',4,0,1,2,14.76,18.94,100,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Observation\n",
    "request = {\n",
    "    \"instances\": [\n",
    "        # First instance.\n",
    "        {\n",
    "            \"features\": sample_one\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"instances\": [\n",
      "    {\n",
      "      \"features\": [\n",
      "        \"2012-12-19 17:00:00\",\n",
      "        4,\n",
      "        0,\n",
      "        1,\n",
      "        1,\n",
      "        16.4,\n",
      "        20.455,\n",
      "        50,\n",
      "        26.0027\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(request,indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Observations\n",
    "request = {\n",
    "    \"instances\": [\n",
    "        # First instance.\n",
    "        {\n",
    "            \"features\": sample_one\n",
    "        },\n",
    "        # Second instance.\n",
    "        {\n",
    "            \"features\": sample_two\n",
    "        },\n",
    "        # Third instance.\n",
    "        {\n",
    "            \"features\": sample_three\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"instances\": [\n",
      "    {\n",
      "      \"features\": [\n",
      "        \"2012-12-19 17:00:00\",\n",
      "        4,\n",
      "        0,\n",
      "        1,\n",
      "        1,\n",
      "        16.4,\n",
      "        20.455,\n",
      "        50,\n",
      "        26.0027\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"features\": [\n",
      "        \"2012-12-19 18:00:00\",\n",
      "        4,\n",
      "        0,\n",
      "        1,\n",
      "        1,\n",
      "        15.58,\n",
      "        19.695,\n",
      "        50,\n",
      "        23.9994\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"features\": [\n",
      "        \"2012-12-10 01:00:00\",\n",
      "        4,\n",
      "        0,\n",
      "        1,\n",
      "        2,\n",
      "        14.76,\n",
      "        18.94,\n",
      "        100,\n",
      "        0\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(request,indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data Structure: \n",
    "# datetime,season,holiday,workingday,weather,temp,atemp,humidity,windspeed,casual,registered,count\n",
    "\n",
    "# Model expects data in this format (it was trained with these features):\n",
    "# season,holiday,workingday,weather,temp,atemp,humidity,windspeed,year,month,day,dayofweek,hour\n",
    "\n",
    "def transform_data(data):\n",
    "    features = data.copy()\n",
    "    # Extract year, month, day, dayofweek, hour\n",
    "    dt = dateutil.parser.parse(features[0])\n",
    "\n",
    "    features.append(dt.year)\n",
    "    features.append(dt.month)\n",
    "    features.append(dt.day)\n",
    "    features.append(dt.weekday())\n",
    "    features.append(dt.hour)\n",
    "    \n",
    "    # Return the transformed data. skip datetime field\n",
    "    return ','.join([str(feature) for feature in features[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data:\n",
      " ['2012-12-19 17:00:00', 4, 0, 1, 1, 16.4, 20.455, 50, 26.0027]\n",
      "Transformed Data:\n",
      " 4,0,1,1,16.4,20.455,50,26.0027,2012,12,19,2,17\n"
     ]
    }
   ],
   "source": [
    "print('Raw Data:\\n',sample_one)\n",
    "print('Transformed Data:\\n',transform_data(sample_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single with error\n",
    "request = {\n",
    "    \"instances\": [\n",
    "        # First instance.\n",
    "        {\n",
    "            \"features\": [\"hi there\",0,2]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when transforming: Unknown string format: hi there\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    transformed_data = [transform_data(instance['features']) for instance in request[\"instances\"]]\n",
    "except Exception as err:\n",
    "    print('Error when transforming: {0}'.format(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Observation\n",
    "request = {\n",
    "    \"instances\": [\n",
    "        # First instance.\n",
    "        {\n",
    "            \"features\": sample_one\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's invoke prediction now\n",
    "result = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                       Body=transform_data(request['instances'][0]['features']).encode('utf-8'),\n",
    "                       ContentType='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result['Body'].read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Count 1.329240521840346e+249\n"
     ]
    }
   ],
   "source": [
    "# Model was trained with log1p(count)\n",
    "# So, we need to apply inverse transformation to get the actual count\n",
    "# Predicted Count looks much better now\n",
    "print ('Predicted Count', math.expm1(float(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Observations\n",
    "request = {\n",
    "    \"instances\": [\n",
    "        # First instance.\n",
    "        {\n",
    "            \"features\": sample_one\n",
    "        },\n",
    "        # Second instance.\n",
    "        {\n",
    "            \"features\": sample_two\n",
    "        },\n",
    "        # Third instance.\n",
    "        {\n",
    "            \"features\": sample_three\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'features': ['2012-12-19 17:00:00', 4, 0, 1, 1, 16.4, 20.455, 50, 26.0027]}\n",
      "Transformed:\n",
      "  4,0,1,1,16.4,20.455,50,26.0027,2012,12,19,2,17\n",
      "{'features': ['2012-12-19 18:00:00', 4, 0, 1, 1, 15.58, 19.695, 50, 23.9994]}\n",
      "Transformed:\n",
      "  4,0,1,1,15.58,19.695,50,23.9994,2012,12,19,2,18\n",
      "{'features': ['2012-12-10 01:00:00', 4, 0, 1, 2, 14.76, 18.94, 100, 0]}\n",
      "Transformed:\n",
      "  4,0,1,2,14.76,18.94,100,0,2012,12,10,0,1\n"
     ]
    }
   ],
   "source": [
    "for instance in request[\"instances\"]:\n",
    "    print(instance)\n",
    "    print('Transformed:')\n",
    "    print(' ', transform_data(instance['features']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost accepts data in CSV. It does not support JSON.\n",
    "# So, we need to submit the request in CSV format\n",
    "# Prediction for multiple observations in the same call\n",
    "result = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                       Body=('\\n'.join(\n",
    "                           [transform_data(instance['features']) \n",
    "                                for instance in request[\"instances\"]]).encode('utf-8')),\n",
    "                       ContentType='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['573.6282958984375', '547.5216064453125', '10.423816680908203', '']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result['Body'].read()\n",
    "pattern = r'[^0-9.]+'\n",
    "re.split(pattern, result.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = result.split(',')\n",
    "predictions = [math.expm1(float(r)) for r in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0413759433029089e+23,\n",
       " 7.694785265142018e+23,\n",
       " 1.4093490824269389e+22,\n",
       " 9.496119420602448e+19,\n",
       " 2.830753303274694e+23,\n",
       " 5.184705528587072e+21,\n",
       " 2.091659496012996e+24,\n",
       " 5.184705528587072e+21,\n",
       " 5.685719999335932e+24,\n",
       " 1.0413759433029089e+23,\n",
       " 2.091659496012996e+24,\n",
       " 5.685719999335932e+24,\n",
       " 2.091659496012996e+24,\n",
       " 3.831008000716577e+22,\n",
       " 1.4093490824269389e+22,\n",
       " 7.694785265142018e+23,\n",
       " 1.0413759433029089e+23,\n",
       " 22025.465794806718,\n",
       " 1.0413759433029089e+23,\n",
       " 3.831008000716577e+22,\n",
       " 7.694785265142018e+23,\n",
       " 9.496119420602448e+19,\n",
       " 1.0413759433029089e+23,\n",
       " 5.184705528587072e+21,\n",
       " 1.9073465724950998e+21,\n",
       " 2.830753303274694e+23,\n",
       " 7.016735912097631e+20,\n",
       " 2.830753303274694e+23,\n",
       " 3.831008000716577e+22,\n",
       " 3.831008000716577e+22,\n",
       " 1.0413759433029089e+23,\n",
       " 1.4093490824269389e+22,\n",
       " 1.9073465724950998e+21,\n",
       " 5.184705528587072e+21,\n",
       " 1.0413759433029089e+23,\n",
       " 22025.465794806718,\n",
       " 1.9073465724950998e+21,\n",
       " 7.016735912097631e+20,\n",
       " 9.496119420602448e+19,\n",
       " 3.831008000716577e+22,\n",
       " 5.184705528587072e+21,\n",
       " 1.4093490824269389e+22,\n",
       " 2.091659496012996e+24,\n",
       " 1.9073465724950998e+21,\n",
       " 2.830753303274694e+23,\n",
       " 2.830753303274694e+23,\n",
       " 2.091659496012996e+24,\n",
       " 7.016735912097631e+20,\n",
       " 5.685719999335932e+24,\n",
       " 7.016735912097631e+20,\n",
       " 2.091659496012996e+24,\n",
       " 5.184705528587072e+21,\n",
       " 7.016735912097631e+20,\n",
       " 1.4093490824269389e+22,\n",
       " 22025.465794806718]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}